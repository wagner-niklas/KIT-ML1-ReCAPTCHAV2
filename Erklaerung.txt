Erklärung zum Programm und zur Vorgehensweise bei der Projektabgabe in Maschinelles Lernen 1, WS22/23

u-Kürzel: ujrrg, uvssk, ubfgn


Programm: 

- Laden aller verwendeten Module
- Definition aller eingesetzten Hyperparameter
- Google Drive mounten und Daten importieren
- Definition der Transformationen (getrennt für je Trainings-, Validierungs- und Testdaten)
- Aufteilung der Train_Val Daten in Train und Val Ordner auf Ordnerebene, um getrennte Imagefolder (mit verschiedenen Transformationen) erstellen zu können
- Erstellung der Datensets und DataLoader
- Funktion zum Laden eines Swin Transformers mit vortrainierten Gewichten und Optimierer
- Funktionen zum Training und Validieren
- Durchführen des Trainings mit 3 Alternativen: Gesamtes Model (alle Parameter), nur Klassifizierer oder beides nacheinander
- Speichern des Modells in Google Drive 
- Dokumentation der Hyperparameter und Transformationen als txt-Datei in Google Drive (siehe auch unten in diesem Dokument)
- Erstellung der csv-Datei auf dem Testdatensatz


Vorgehensweise:

- Modell: 
	- Swin Transformer v2 small, da Vision Transformer aktuell die Benchmarks dominieren 
- Datensatz:
	- getrennte Transformationen für Trainings- und Validerungsdaten, blieb jedoch ohne Erfolg
	- die meisten ausprobierten Data Augmentations blieben ebenfalls ohne Erfolg
	- verwendet wurden nur RandomHorizontalFlip, RandomRotation und RandomGrayscale
- Training: 
	- eine eher kleine Lernrate, Lernraten Decay und vor allem das Training des gesamten Modells anstatt nur des Klassifizierers brachten große Fortschritte
	- das "Finetuning" durch Training des Klassifizieres alleine, nachdem alle Parameter trainiert wurden, brachte selten Fortschritte
	- Implementierung von Early Stopping und Visualisierung der Loss-Verläufe während des Trainings waren hilfreich
	- Ohne Erfolg blieb das Testen eines ImbalancedDatasetSampler, der die Genauigkeit auf schwach repräsentierten Klassen verbessern sollte


Dokumentation der Hyperparameter zum Model swin_transformer_s.

- Erreichte Genauigkeit auf den Validierungsdaten: 86.67%
- Erreichte Genauigkeit auf den Testdaten: 87,43%

- train_percentage = 0.85
- batchsize = 32
- use_imbalanced_dataset_sampler = False
- learning_rate_1 = 5e-05
- learning_rate_2 = 1e-05
- step_size = 1
- gamma = 0.85
- dropout_prob = 0.3
- alternative = 3
- early_stopping_limit = 12


- Data Augmentations/Transformations:

train_dataset:
<bound method Compose.__repr__ of Compose(
    RandomHorizontalFlip(p=0.5)
    RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)
    CenterCrop(size=(120, 120))
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    RandomGrayscale(p=0.01)
)>

val_dataset:
<bound method Compose.__repr__ of Compose(
    CenterCrop(size=(120, 120))
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)>

test_dataset:
<bound method Compose.__repr__ of Compose(
    CenterCrop(size=(120, 120))
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)>